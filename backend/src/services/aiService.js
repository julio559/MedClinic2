// src/services/aiService.js
const { Analysis, AnalysisResult, MedicalImage, Patient } = require('../models');
const OpenAI = require('openai');
const fs = require('fs');
const path = require('path');

// ===== Modelos configur√°veis (ENV) =====
const MODEL_TEXT   = process.env.OPENAI_TEXT_MODEL   || 'gpt-4o';
const MODEL_VISION = process.env.OPENAI_VISION_MODEL || MODEL_TEXT;

// ===== OpenAI =====
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// ===== Constantes de estrutura =====
const REQUIRED_CATEGORIES = [
  'diagnostico_principal',
  'etiologia',
  'fisiopatologia',
  'apresentacao_clinica',
  'abordagem_diagnostica',
  'abordagem_terapeutica',
  'guia_prescricao'
];

const JSON_SCHEMA_TEXT = `
Objeto JSON com 7 chaves obrigat√≥rias:
{
  "diagnostico_principal": { "resultado": string, "confianca": number (0..1), "justificativa": string },
  "etiologia": { "resultado": string, "confianca": number (0..1), "justificativa": string },
  "fisiopatologia": { "resultado": string, "confianca": number (0..1), "justificativa": string },
  "apresentacao_clinica": { "resultado": string, "confianca": number (0..1), "justificativa": string },
  "abordagem_diagnostica": { "resultado": string, "confianca": number (0..1), "justificativa": string },
  "abordagem_terapeutica": { "resultado": string, "confianca": number (0..1), "justificativa": string },
  "guia_prescricao": { "resultado": string, "confianca": number (0..1), "justificativa": string }
}
- Todas as chaves s√£o obrigat√≥rias.
- "confianca" deve ser um n√∫mero entre 0 e 1.
- Responder APENAS com JSON v√°lido (sem crases, sem coment√°rios).
`.trim();

// ===== Servi√ßo principal =====
const processWithAI = async (analysisId) => {
  try {
    const analysis = await Analysis.findByPk(analysisId, {
      include: [{ model: MedicalImage }, { model: Patient }]
    });
    if (!analysis) throw new Error('An√°lise n√£o encontrada');
    if (!process.env.OPENAI_API_KEY) throw new Error('OPENAI_API_KEY ausente. Configure e tente novamente.');

    console.log(`ü§ñ Iniciando an√°lise de IA M√âDICA para: ${analysis.title}`);
    await analysis.update({ status: 'processing' });

    const medicalPrompt = buildMedicalPrompt(analysis);

    let imageAnalysis = '';
    if (analysis.MedicalImages && analysis.MedicalImages.length > 0) {
      imageAnalysis = await analyzeImages(analysis.MedicalImages);
    }

    // Gera√ß√£o SEM MOCK
    const aiAnalysis = await performMedicalAnalysis(medicalPrompt, imageAnalysis);

    const savedResults = await saveAnalysisResults(analysis.id, aiAnalysis);
    const avgConfidence = savedResults.reduce((acc, r) => acc + r.confidenceScore, 0) / savedResults.length;

    await analysis.update({ status: 'completed', aiConfidenceScore: avgConfidence });

    console.log(`‚úÖ An√°lise conclu√≠da: ${analysis.title} (${Math.round(avgConfidence * 100)}% confian√ßa)`);

    if (global.socketIO) {
      global.socketIO.to(`doctor_${analysis.doctorId}`).emit('analysis_completed', {
        analysisId: analysis.id,
        title: analysis.title,
        confidence: avgConfidence,
        resultsCount: savedResults.length,
        message: 'An√°lise de IA m√©dica conclu√≠da!'
      });
    }

    return { success: true, analysisId: analysis.id, confidence: avgConfidence, resultsCount: savedResults.length };

  } catch (error) {
    console.error('‚ùå Erro no processamento de IA:', error);
    await Analysis.update({ status: 'failed' }, { where: { id: analysisId } });
    throw error;
  }
};

// ===== Prompt base =====
const buildMedicalPrompt = (analysis) => {
  const patient = analysis.Patient;
  return `SISTEMA DE APOIO DIAGN√ìSTICO PARA M√âDICOS - AN√ÅLISE CL√çNICA ESPECIALIZADA

IMPORTANTE: Uso exclusivo por m√©dicos licenciados; apoio ao diagn√≥stico; n√£o substitui julgamento cl√≠nico.

DADOS CL√çNICOS DO PACIENTE:
- Nome: ${patient?.name || 'Paciente n√£o identificado'}
- Idade: ${patient?.birthDate ? calculateAge(patient.birthDate) : 'Idade n√£o informada'}
- Sexo: ${patient?.gender || 'N√£o informado'}
- Hist√≥ria m√©dica pregressa: ${patient?.medicalHistory || 'N√£o informada'}
- Alergias conhecidas: ${patient?.allergies || 'N√£o informadas'}

APRESENTA√á√ÉO CL√çNICA ATUAL:
- Motivo da consulta: ${analysis.title}
- Hist√≥ria da doen√ßa atual: ${analysis.description || 'N√£o fornecida'}
- Sintomas/achados: ${analysis.symptoms || 'N√£o fornecidos'}

INSTRU√á√ïES:
Forne√ßa an√°lise m√©dica baseada em evid√™ncias, terminologia t√©cnica e formato JSON abaixo (sem texto extra).
${JSON_SCHEMA_TEXT}

RESPONDA EXCLUSIVAMENTE COM JSON V√ÅLIDO.`;
};

// ===== Imagens (usa modelo com vis√£o; gpt-4o aceita imagem) =====
const analyzeImages = async (medicalImages) => {
  try {
    console.log(`üñºÔ∏è Analisando ${medicalImages.length} imagem(ns) com ${MODEL_VISION}`);
    const imageAnalyses = [];

    for (const image of medicalImages) {
      try {
        if (!fs.existsSync(image.filePath)) {
          console.warn(`Arquivo n√£o encontrado: ${image.filePath}`);
          continue;
        }
        const imageBuffer = fs.readFileSync(image.filePath);
        const base64Image = imageBuffer.toString('base64');
        const mimeType = image.mimeType || 'image/jpeg';

        const response = await openai.chat.completions.create({
          model: MODEL_VISION, // <- era gpt-4-vision-preview
          messages: [
            {
              role: "system",
              content: "Voc√™ √© um radiologista especialista. Produza um laudo t√©cnico e objetivo para m√©dicos."
            },
            {
              role: "user",
              content: [
                {
                  type: "text",
                  text:
`Gerar laudo radiol√≥gico detalhado:
1) T√©cnica/qualidade; 2) Anatomia; 3) Achados; 4) Localiza√ß√£o; 5) Morfologia; 6) Hip√≥teses; 7) Exames adicionais.`
                },
                {
                  type: "image_url",
                  image_url: { url: `data:${mimeType};base64,${base64Image}` }
                }
              ]
            }
          ],
          max_tokens: 2000,
          temperature: 0.1
        });

        const imageAnalysis = response.choices?.[0]?.message?.content || '(sem conte√∫do)';
        imageAnalyses.push({
          filename: image.originalName,
          type: image.imageType,
          analysis: imageAnalysis
        });

        console.log(`‚úÖ Laudo gerado: ${image.originalName}`);
      } catch (err) {
        console.error(`Erro em ${image.originalName}:`, err?.message || err);
      }
    }

    if (imageAnalyses.length === 0) return '';
    return (
      `\n\nRELAT√ìRIO RADIOL√ìGICO DAS IMAGENS ANEXADAS:\n` +
      imageAnalyses.map(img =>
        `\n=== IMAGEM: ${img.filename} (Tipo: ${img.type}) ===\n${img.analysis}\n`
      ).join('\n')
    );
  } catch (error) {
    console.error('Erro na an√°lise radiol√≥gica:', error);
    return '';
  }
};

// ===== Gera√ß√£o principal SEM MOCK =====
const performMedicalAnalysis = async (prompt, imageAnalysis) => {
  const fullPrompt = `${prompt}${imageAnalysis || ''}`.trim();

  let aiContent = await callAIForJSON(fullPrompt);
  let data = tryParseJSON(aiContent);

  if (!data) {
    aiContent = await repairJsonWithAI(aiContent);
    data = tryParseJSON(aiContent);
  }
  if (!data) {
    aiContent = await regenerateAnalysisWithAI(fullPrompt);
    data = tryParseJSON(aiContent);
  }
  if (!data) {
    aiContent = await regenerateAnalysisWithAI(fullPrompt, /*minimal=*/true);
    data = tryParseJSON(aiContent);
  }
  if (!data) throw new Error('Falha ao obter JSON v√°lido da IA.');

  const missing = REQUIRED_CATEGORIES.filter(k => !data[k] || !data[k].resultado);
  if (missing.length > 0) {
    aiContent = await fillMissingCategoriesWithAI(data, missing);
    data = tryParseJSON(aiContent) || data;
  }

  for (const c of REQUIRED_CATEGORIES) {
    if (data[c]?.confianca !== undefined) {
      const v = Number(data[c].confianca);
      data[c].confianca = Number.isFinite(v) ? Math.min(Math.max(v, 0), 1) : 0.75;
    } else if (data[c]) {
      data[c].confianca = 0.75;
    }
  }

  return data;
};

// ===== Chamadas auxiliares √† IA =====
async function callAIForJSON(userContent) {
  console.log('üß† Solicitando JSON √† IA com', MODEL_TEXT);
  const resp = await openai.chat.completions.create({
    model: MODEL_TEXT, // <- era gpt-4-turbo-preview
    messages: [
      {
        role: "system",
        content:
          "Voc√™ √© um sistema de IA m√©dica para apoio diagn√≥stico. Responda APENAS com JSON v√°lido conforme o schema fornecido."
      },
      { role: "user", content: userContent }
    ],
    temperature: 0.2,
    max_tokens: 4000,
    response_format: { type: "json_object" }
  });
  const content = resp.choices?.[0]?.message?.content ?? '';
  console.log('‚úÖ Resposta IA recebida (tamanho):', content.length);
  return content;
}

async function repairJsonWithAI(invalidContent) {
  console.log('üß© Reparando JSON inv√°lido com', MODEL_TEXT);
  const prompt = `
O conte√∫do abaixo N√ÉO √© JSON v√°lido ou viola o schema. Conserte para JSON V√ÅLIDO e COMPLETE todas as chaves obrigat√≥rias.

SCHEMA:
${JSON_SCHEMA_TEXT}

CONTE√öDO PARA REPARO (N√ÉO repita nada fora do JSON):
${invalidContent}

Responda SOMENTE com JSON v√°lido.
  `.trim();

  const resp = await openai.chat.completions.create({
    model: MODEL_TEXT,
    messages: [
      { role: "system", content: "Voc√™ conserta JSON para ficar estritamente v√°lido segundo um schema. Responda apenas JSON." },
      { role: "user", content: prompt }
    ],
    temperature: 0,
    max_tokens: 3500,
    response_format: { type: "json_object" }
  });
  return resp.choices?.[0]?.message?.content ?? '';
}

async function regenerateAnalysisWithAI(fullPrompt, minimal = false) {
  console.log('üîÅ Regenerando an√°lise com', MODEL_TEXT);
  const tighten = minimal ? 'Forne√ßa texto objetivo e conciso em cada campo.' : 'Forne√ßa justificativas cl√≠nicas robustas.';
  const prompt = `
Refa√ßa a resposta obedecendo ao SCHEMA e √†s DIRETRIZES. Responda SOMENTE com JSON.

DIRETRIZES:
- Terminologia m√©dica, evid√™ncia cl√≠nica, objetividade.
- "confianca" entre 0 e 1.
- Sem texto fora do JSON.

SCHEMA:
${JSON_SCHEMA_TEXT}

CASO CL√çNICO:
${fullPrompt}

${tighten}
  `.trim();

  const resp = await openai.chat.completions.create({
    model: MODEL_TEXT,
    messages: [
      { role: "system", content: "Voc√™ √© IA m√©dica; gere JSON estritamente v√°lido conforme schema. Sem texto extra." },
      { role: "user", content: prompt }
    ],
    temperature: minimal ? 0.1 : 0.2,
    max_tokens: 3800,
    response_format: { type: "json_object" }
  });
  return resp.choices?.[0]?.message?.content ?? '';
}

async function fillMissingCategoriesWithAI(partialObj, missingKeys) {
  console.log('üß© Completando categorias faltantes com', MODEL_TEXT, '->', missingKeys);
  const prompt = `
Complete as categorias faltantes no objeto abaixo, obedecendo o SCHEMA e mantendo o estilo/n√≠vel de detalhe.
Retorne o OBJETO COMPLETO (todas as 7 categorias). Responda SOMENTE com JSON.

SCHEMA:
${JSON_SCHEMA_TEXT}

CATEGORIAS FALTANTES: ${missingKeys.join(', ')}

OBJETO PARCIAL:
${JSON.stringify(partialObj)}
  `.trim();

  const resp = await openai.chat.completions.create({
    model: MODEL_TEXT,
    messages: [
      { role: "system", content: "Voc√™ completa JSONs m√©dicos para aderir ao schema. Responda apenas JSON." },
      { role: "user", content: prompt }
    ],
    temperature: 0.2,
    max_tokens: 3500,
    response_format: { type: "json_object" }
  });
  return resp.choices?.[0]?.message?.content ?? '';
}

// ===== Persist√™ncia =====
const saveAnalysisResults = async (analysisId, aiAnalysis) => {
  console.log('üíæ Salvando resultados da an√°lise m√©dica...');
  const categoryMapping = {
    'diagnostico_principal': 'Diagn√≥stico Principal',
    'etiologia': 'Etiologia',
    'fisiopatologia': 'Fisiopatologia',
    'apresentacao_clinica': 'Apresenta√ß√£o Cl√≠nica',
    'abordagem_diagnostica': 'Abordagem Diagn√≥stica',
    'abordagem_terapeutica': 'Abordagem Terap√™utica',
    'guia_prescricao': 'Guia de Prescri√ß√£o'
  };

  const savedResults = [];
  for (const [key, name] of Object.entries(categoryMapping)) {
    const cat = aiAnalysis[key];
    if (!cat || !cat.resultado) continue;

    const result = await AnalysisResult.create({
      category: name,
      result: String(cat.resultado),
      confidenceScore: clamp01(Number(cat.confianca ?? 0.75)),
      aiModel: `${MODEL_TEXT} (texto) + ${MODEL_VISION} (imagem)`,
      isCompleted: true,
      analysisId
    });

    savedResults.push(result);
    console.log(`‚úÖ ${name}: ${Math.round(result.confidenceScore * 100)}% confian√ßa`);
  }

  console.log(`üíæ ${savedResults.length} resultados salvos`);
  return savedResults;
};

// ===== Utilit√°rios =====
const clamp01 = (n) => (Number.isFinite(n) ? Math.min(Math.max(n, 0), 1) : 0.75);

const calculateAge = (birthDate) => {
  const today = new Date();
  const birth = new Date(birthDate);
  let age = today.getFullYear() - birth.getFullYear();
  const m = today.getMonth() - birth.getMonth();
  if (m < 0 || (m === 0 && today.getDate() < birth.getDate())) age--;
  return `${age} anos`;
};

const tryParseJSON = (txt) => {
  if (!txt || typeof txt !== 'string') return null;
  try { return JSON.parse(txt); } catch { return null; }
};

const validateOpenAIConfig = () => {
  const key = process.env.OPENAI_API_KEY;
  if (!key) {
    console.error('‚ùå OPENAI_API_KEY n√£o configurada no .env');
    return false;
  }
  if (!/^sk-/.test(key)) {
    console.error('‚ùå OPENAI_API_KEY inv√°lida (deve come√ßar com "sk-")');
    return false;
  }
  console.log('‚úÖ OpenAI configurada');
  console.log('‚ÑπÔ∏è Modelos em uso:', { MODEL_TEXT, MODEL_VISION });
  return true;
};

// ===== Exports =====
module.exports = {
  processWithAI,
  validateOpenAIConfig,
  testOpenAIConnection: async () => {
    try {
      if (!process.env.OPENAI_API_KEY) return false;
      const res = await openai.chat.completions.create({
        model: MODEL_TEXT,
        messages: [{ role: "user", content: "Responda apenas: OK" }],
        max_tokens: 5
      });
      return (res.choices?.[0]?.message?.content || '').trim().startsWith('OK');
    } catch {
      return false;
    }
  }
};
